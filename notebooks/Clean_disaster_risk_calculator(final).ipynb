{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9faebb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def process_world_risk_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    id_vars = ['WRI.Country']\n",
    "    value_vars = [col for col in df.columns if '_' in col and col.split('_')[-1].isdigit()]\n",
    "\n",
    "    df_long = df.melt(id_vars=id_vars, value_vars=value_vars,\n",
    "                      var_name='Indicator_Year', value_name='Value')\n",
    "\n",
    "    df_long[['Indicator', 'Year']] = df_long['Indicator_Year'].str.split('_', expand=True)\n",
    "    df_long['Year'] = df_long['Year'].astype(int)\n",
    "\n",
    "    final_df = df_long.pivot_table(index=['WRI.Country', 'Year'],\n",
    "                                   columns='Indicator',\n",
    "                                   values='Value').reset_index()\n",
    "\n",
    "    df.rename(columns={\"WRI.Country\": \"Country\"}, inplace=True)\n",
    "    \n",
    "    multiple_columns_drop = [\n",
    "        \"EI_01a_Norm\", \"EI_01a_Base\", \"EI_01b_Norm\", \"EI_01b_Base\", \"EI_01c_Norm\", \"EI_01c_Base\", \n",
    "        \"EI_01d_Norm\", \"EI_01d_Base\", \"EI_01e_Norm\", \"EI_01e_Base\", \"EI_01f_Norm\", \"EI_01f_Base\",\n",
    "        \"EI_02a_Norm\", \"EI_02a_Base\", \"EI_02b_Norm\", \"EI_02b_Base\", \"EI_02c_Norm\", \"EI_02c_Base\",\n",
    "        \"EI_02d_Norm\", \"EI_02d_Base\", \"EI_02e_Norm\", \"EI_02e_Base\", \"EI_02f_Norm\", \"EI_02f_Base\",\n",
    "        \"EI_03a_Norm\", \"EI_03a_Base\", \"EI_03b_Norm\", \"EI_03b_Base\", \"EI_03c_Norm\", \"EI_03c_Base\",\n",
    "        \"EI_03d_Base\", \"EI_03d_Norm\", \"EI_03e_Base\", \"EI_03e_Norm\", \"EI_03f_Base\", \"EI_03f_Norm\",\n",
    "        \"EI_04a_Norm\", \"EI_04a_Base\", \"EI_04b_Norm\", \"EI_04b_Base\", \"EI_04c_Norm\", \"EI_04c_Base\",\n",
    "        \"EI_04d_Norm\", \"EI_04d_Base\", \"EI_04e_Norm\", \"EI_04e_Base\", \"EI_04f_Norm\", \"EI_04f_Base\",\n",
    "        \"EI_05a_Norm\", \"EI_05a_Base\", \"EI_05b_Norm\", \"EI_05b_Base\", \"EI_05c_Norm\", \"EI_05c_Base\",\n",
    "        \"EI_05d_Norm\", \"EI_05d_Base\", \"EI_05e_Norm\", \"EI_05e_Base\", \"EI_05f_Norm\", \"EI_05f_Base\",\n",
    "        \"EI_06a_Norm\", \"EI_06a_Base\", \"EI_06b_Norm\", \"EI_06b_Base\", \"EI_06c_Norm\", \"EI_06c_Base\",\n",
    "        \"EI_06d_Norm\", \"EI_06d_Base\", \"EI_06e_Norm\", \"EI_06e_Base\", \"EI_06f_Norm\", \"EI_06f_Base\",\n",
    "        \"EI_07a_Norm\", \"EI_07a_Base\", \"EI_07b_Norm\", \"EI_07b_Base\", \"SI_01a_Norm\", \"SI_01a_Base\",\n",
    "        \"SI_01b_Norm\", \"SI_01b_Base\", \"SI_02a_Norm\", \"SI_02a_Base\", \"SI_02b_Norm\", \"SI_02b_Base\",\n",
    "        \"SI_03a_Norm\", \"SI_03a_Base\", \"SI_03b_Norm\", \"SI_03b_Base\", \"SI_04a_Norm\", \"SI_04a_Base\",\n",
    "        \"SI_04b_Norm\", \"SI_04b_Base\", \"SI_05a_Norm\", \"SI_05a_Base\", \"SI_05b_Norm\", \"SI_05b_Base\",\n",
    "        \"SI_06a_Norm\", \"SI_06a_Base\", \"SI_06b_Norm\", \"SI_06b_Base\", \"SI_07a_Norm\", \"SI_07a_Base\",\n",
    "        \"SI_07b_Norm\", \"SI_07b_Base\", \"SI_08a_Norm\", \"SI_08a_Base\", \"SI_08b_Norm\", \"SI_08b_Base\",\n",
    "        \"SI_09a_Norm\", \"SI_09a_Base\", \"SI_09b_Norm\", \"SI_09b_Base\", \"SI_10_Norm\", \"SI_10_Base\",\n",
    "        \"SI_10a_Norm\", \"SI_10a_Base\", \"SI_10b_Norm\", \"SI_10b_Base\", \"SI_11_Norm\", \"SI_11_Base\",\n",
    "        \"SI_12a_Norm\", \"SI_12a_Base\", \"SI_12b_Norm\", \"SI_12b_Base\", \"SI_13a_Norm\", \"SI_13a_Base\",\n",
    "        \"SI_13b_Norm\", \"SI_13b_Base\", \"SI_14a_Norm\", \"SI_14a_Base\", \"SI_14b_Norm\", \"SI_14b_Base\",\n",
    "        \"SI_15a_Norm\", \"SI_15a_Base\", \"SI_15b_Norm\", \"SI_15b_Base\", \"SI_15c_Norm\", \"SI_15c_Base\",\n",
    "        \"SI_15d_Norm\", \"SI_15d_Base\", \"CI_01a_Norm\", \"CI_01a_Base\", \"CI_01b_Norm\", \"CI_01b_Base\",\n",
    "        \"CI_02a_Norm\", \"CI_02a_Base\", \"CI_02b_Norm\", \"CI_02b_Base\", \"CI_03a_Norm\", \"CI_03a_Base\",\n",
    "        \"CI_03b_Norm\", \"CI_03b_Base\", \"CI_04a_Norm\", \"CI_04a_Base\", \"CI_04b_Norm\", \"CI_04b_Base\",\n",
    "        \"CI_05a_Norm\", \"CI_05a_Base\", \"CI_05b_Norm\", \"CI_05b_Base\", \"CI_06a_Norm\", \"CI_06a_Base\",\n",
    "        \"CI_06b_Norm\", \"CI_06b_Base\", \"CI_07a_Norm\", \"CI_07a_Base\", \"CI_07b_Norm\", \"CI_07b_Base\",\n",
    "        \"AI_01a_Norm\", \"AI_01a_Base\", \"AI_01b_Norm\", \"AI_01b_Base\", \"AI_01c_Norm\", \"AI_01c_Base\",\n",
    "        \"AI_02a_Norm\", \"AI_02a_Base\", \"AI_02b_Norm\", \"AI_02b_Base\", \"AI_02c_Norm\", \"AI_02c_Base\",\n",
    "        \"AI_03a_Norm\", \"AI_03a_Base\", \"AI_03b_Norm\", \"AI_03b_Base\", \"AI_03c_Norm\", \"AI_03c_Base\",\n",
    "        \"AI_04a_Norm\", \"AI_04a_Base\", \"AI_04b_Norm\", \"AI_04b_Base\", \"AI_04c_Norm\", \"AI_04c_Base\",\n",
    "        \"AI_05a_Norm\", \"AI_05a_Base\", \"AI_05b_Norm\", \"AI_05b_Base\"\n",
    "    ]\n",
    "    \n",
    "    df.drop(multiple_columns_drop, axis='columns', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d482f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_world_risk_data(\"worldriskindex-trend.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87d740aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_disaster_data(file_name):\n",
    "    df_disasters = pd.read_excel(file_name)\n",
    "    \n",
    "    df_disasters['Year'] = df_disasters['DisNo.'].str[:4].astype(int)\n",
    "\n",
    "    columns_to_drop = [\n",
    "        \"External IDs\", \"Event Name\", \"AID Contribution ('000 US$)\", \n",
    "        \"Reconstruction Costs ('000 US$)\", \"Origin\", \"Associated Types\", \n",
    "        \"Latitude\", \"Longitude\", \"River Basin\", \"No. Injured\", \"No. Affected\", \n",
    "        \"No. Homeless\", \"Reconstruction Costs, Adjusted ('000 US$)\", \n",
    "        \"Insured Damage ('000 US$)\", \"Insured Damage, Adjusted ('000 US$)\", \n",
    "        \"Total Damage ('000 US$)\", \"Total Damage, Adjusted ('000 US$)\"\n",
    "    ]\n",
    "    df_disasters.drop(columns_to_drop, axis='columns', inplace=True)\n",
    "\n",
    "    df_disasters['Start_Date'] = pd.to_datetime(dict(\n",
    "        year=df_disasters['Start Year'],\n",
    "        month=df_disasters['Start Month'],\n",
    "        day=df_disasters['Start Day']\n",
    "    ), errors='coerce')\n",
    "\n",
    "    df_disasters['End_Date'] = pd.to_datetime(dict(\n",
    "        year=df_disasters['End Year'],\n",
    "        month=df_disasters['End Month'],\n",
    "        day=df_disasters['End Day']\n",
    "    ), errors='coerce')\n",
    "\n",
    "    df_disasters['Disaster_Duration_Days'] = (df_disasters['End_Date'] - df_disasters['Start_Date']).dt.days\n",
    "\n",
    "    dropping_columns = [\n",
    "        \"Historic\", \"Disaster Group\", \"Last Update\", \"Entry Date\", \n",
    "        \"Admin Units\", \"DisNo.\", \"Magnitude\", \"Magnitude Scale\", \n",
    "        \"Start Year\", \"Start Day\", \"End Year\", \"End Day\", \n",
    "        \"End_Date\", \"Start_Date\", \"OFDA/BHA Response\", \"Appeal\", \n",
    "        \"Declaration\", \"Location\"\n",
    "    ]\n",
    "    \n",
    "    df_disasters.drop(dropping_columns, axis='columns', inplace=True)\n",
    "    \n",
    "    df_disasters.columns = df_disasters.columns.str.strip()\n",
    "\n",
    "    df_disasters['Disaster_Duration_Days'] = df_disasters.groupby('Disaster Subtype')['Disaster_Duration_Days']\\\n",
    "        .transform(lambda x: x.fillna(x.mean()))\n",
    "    df_disasters['Total Deaths'] = df_disasters.groupby('Disaster Subtype')['Total Deaths'].transform(lambda x: x.fillna(x.mean()))\n",
    "    df_disasters['Total Affected'] = df_disasters.groupby('Disaster Subtype')['Total Affected'].transform(lambda x: x.fillna(x.mean()))\n",
    "    df_disasters['CPI'] = df_disasters.groupby('Country')['CPI'].transform(lambda x: x.fillna(x.mean()))\n",
    "    df_disasters['Disaster_Duration_Days'] = df_disasters.groupby('Disaster Subtype')['Disaster_Duration_Days'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "    df_disasters['Start Month'].fillna(df_disasters['Start Month'].mode()[0], inplace=True)\n",
    "    df_disasters['End Month'].fillna(df_disasters['End Month'].mode()[0], inplace=True)\n",
    "\n",
    "    df_disasters['Total Deaths'].fillna(df_disasters['Total Deaths'].median(), inplace=True)\n",
    "    df_disasters['Disaster_Duration_Days'].fillna(df_disasters['Disaster_Duration_Days'].median(), inplace=True)\n",
    "    df_disasters['CPI'].fillna(df_disasters['CPI'].median(), inplace=True)\n",
    "    df_disasters['Total Affected'].fillna(df_disasters['Total Affected'].median(), inplace=True)\n",
    "\n",
    "    return df_disasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc8232f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disasters = process_disaster_data(\"global_disaster_dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87dddd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_and_clean_housing_data(filepath: str) -> pd.DataFrame:\n",
    "    df_housing = pd.read_csv(filepath)\n",
    "\n",
    "    likely_placeholder_countries = [\n",
    "        'Andorra', 'Monaco', 'Gibraltar', 'Greenland',\n",
    "        'Bermuda', 'Malta', 'Tuvalu', 'Israel'\n",
    "    ]\n",
    "\n",
    "    df_housing.loc[\n",
    "        (df_housing['Country or Territory Name2'].isin(likely_placeholder_countries)) &\n",
    "        (df_housing['Proportion of urban population living in slums or informal settlements (%) (a)'] == 0), \n",
    "        'Proportion of urban population living in slums or informal settlements (%) (a)'\n",
    "    ] = np.nan\n",
    "\n",
    "    df_housing['Proportion of urban population living in slums or informal settlements (%) (a)'] = (\n",
    "        df_housing.groupby('SDG Sub-Region')[\n",
    "            'Proportion of urban population living in slums or informal settlements (%) (a)'\n",
    "        ].transform(lambda x: x.fillna(x.mean()))\n",
    "    )\n",
    "\n",
    "    df_housing.rename(columns={\n",
    "        'Country or Territory Name2': 'Country',\n",
    "        'Data Reference Year': 'Year'\n",
    "    }, inplace=True)\n",
    "\n",
    "    columns_to_drop = [\n",
    "        \"SDG Goal\", \"SDG Target\", \"SDG Indicator\", \"Country or Territory Name\",\n",
    "        \"SDG Region\", \"SDG Sub-Region\", \"Proportion of urban population living in inadequate housing (%) (b)\",\n",
    "        \"Data Units\", \"Data Source\", \"Footnote\"\n",
    "    ]\n",
    "    df_housing.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "    df_housing.dropna(subset=[\n",
    "        'Proportion of urban population living in slums or informal settlements (%) (a)'\n",
    "    ], inplace=True)\n",
    "\n",
    "    return df_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c28bcd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing = load_and_clean_housing_data(\"sdg_11-1-1_proportion_of_urban_population_in_slums_and_informal_settlements.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbdd51f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_final_dataset(df, df_disasters, df_housing):\n",
    "    import pandas as pd\n",
    "    from functools import reduce\n",
    "\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df_housing.columns = df_housing.columns.str.strip()\n",
    "    df_disasters.columns = df_disasters.columns.str.strip()\n",
    "\n",
    "    disaster_type_counts = df_disasters.groupby(['Country', 'Year', 'Disaster Type']) \\\n",
    "                                       .size().unstack(fill_value=0).reset_index()\n",
    "\n",
    "    deaths_by_type = df_disasters.pivot_table(\n",
    "        index=['Country', 'Year'],\n",
    "        columns='Disaster Type',\n",
    "        values='Total Deaths',\n",
    "        aggfunc='sum'\n",
    "    ).fillna(0).reset_index()\n",
    "\n",
    "    affected_by_type = df_disasters.pivot_table(\n",
    "        index=['Country', 'Year'],\n",
    "        columns='Disaster Type',\n",
    "        values='Total Affected',\n",
    "        aggfunc='sum'\n",
    "    ).fillna(0).reset_index()\n",
    "\n",
    "    avg_duration_by_type = df_disasters.pivot_table(\n",
    "        index=['Country', 'Year'],\n",
    "        columns='Disaster Type',\n",
    "        values='Disaster_Duration_Days',\n",
    "        aggfunc='mean'\n",
    "    ).fillna(0).reset_index()\n",
    "\n",
    "    def rename_pivot_columns(df_pivot, prefix):\n",
    "        return df_pivot.rename(columns={\n",
    "            col: f\"{prefix}_{col}\" for col in df_pivot.columns if col not in ['Country', 'Year']\n",
    "        })\n",
    "\n",
    "    disaster_type_counts = rename_pivot_columns(disaster_type_counts, 'count')\n",
    "    deaths_by_type = rename_pivot_columns(deaths_by_type, 'deaths')\n",
    "    affected_by_type = rename_pivot_columns(affected_by_type, 'affected')\n",
    "    avg_duration_by_type = rename_pivot_columns(avg_duration_by_type, 'duration')\n",
    "\n",
    "    dfs_to_merge = [disaster_type_counts, deaths_by_type, affected_by_type, avg_duration_by_type]\n",
    "    df_disaster_features = reduce(lambda left, right: pd.merge(left, right, on=['Country', 'Year'], how='outer'), dfs_to_merge)\n",
    "\n",
    "    country_subregion = df_disasters[['Country', 'Subregion']].drop_duplicates()\n",
    "    df_disaster_features = df_disaster_features.merge(country_subregion, on='Country', how='left')\n",
    "\n",
    "    final_df = df.merge(df_disaster_features, on=['Country', 'Year'], how=\"left\")\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02d56072",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = prepare_final_dataset(df, df_disasters, df_housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c0ef3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_subregions(final_df):\n",
    "    subregion_mapping = {\n",
    "        'Burkina Faso': 'Sub-Saharan Africa',\n",
    "        'Cape Verde': 'Sub-Saharan Africa',\n",
    "        \"Cote d'Ivoire\": 'Sub-Saharan Africa',\n",
    "        'Democratic Republic of Congo': 'Sub-Saharan Africa',\n",
    "        'Eritrea': 'Sub-Saharan Africa',\n",
    "        'Gabon': 'Sub-Saharan Africa',\n",
    "        'Ghana': 'Sub-Saharan Africa',\n",
    "        'Guinea-Bissau': 'Sub-Saharan Africa',\n",
    "        'Mauritania': 'Sub-Saharan Africa',\n",
    "        'Republic of Congo': 'Sub-Saharan Africa',\n",
    "        'Sao Tome and Principe': 'Sub-Saharan Africa',\n",
    "        'Senegal': 'Sub-Saharan Africa',\n",
    "        'Seychelles': 'Sub-Saharan Africa',\n",
    "        'South Sudan': 'Sub-Saharan Africa',\n",
    "        'Togo': 'Sub-Saharan Africa',\n",
    "        'Botswana': 'Sub-Saharan Africa',\n",
    "        'Burundi': 'Sub-Saharan Africa',\n",
    "        'Djibouti': 'Sub-Saharan Africa',\n",
    "        'Egypt': 'Sub-Saharan Africa',\n",
    "        'Eswatini': 'Sub-Saharan Africa',\n",
    "        'Sierra Leone': 'Sub-Saharan Africa',\n",
    "        'Cameroon': 'Sub-Saharan Africa',\n",
    "        'Chad': 'Sub-Saharan Africa',\n",
    "        'Liberia': 'Sub-Saharan Africa',\n",
    "        'Madagascar': 'Sub-Saharan Africa',\n",
    "        'Zambia': 'Sub-Saharan Africa',\n",
    "        'Malawi': 'Sub-Saharan Africa',\n",
    "        'Benin': 'Sub-Saharan Africa',\n",
    "        'Ethiopia': 'Sub-Saharan Africa',\n",
    "        'Guinea': 'Sub-Saharan Africa',\n",
    "        'Mali': 'Sub-Saharan Africa',\n",
    "        'Uganda': 'Sub-Saharan Africa',\n",
    "        'South Africa': 'Sub-Saharan Africa',\n",
    "        'Sudan': 'Sub-Saharan Africa',\n",
    "        'Equatorial Guinea': 'Sub-Saharan Africa',\n",
    "        \n",
    "        'Antigua and Barbuda': 'Latin America and the Caribbean',\n",
    "        'Bahamas': 'Latin America and the Caribbean',\n",
    "        'Barbados': 'Latin America and the Caribbean',\n",
    "        'Bolivarian Republic of Venezuela': 'Latin America and the Caribbean',\n",
    "        'Dominica': 'Latin America and the Caribbean',\n",
    "        'Dominican Republic': 'Latin America and the Caribbean',\n",
    "        'Grenada': 'Latin America and the Caribbean',\n",
    "        'Guyana': 'Latin America and the Caribbean',\n",
    "        'Saint Kitts and Nevis': 'Latin America and the Caribbean',\n",
    "        'Saint Lucia': 'Latin America and the Caribbean',\n",
    "        'Saint Vincent and the Grenadines': 'Latin America and the Caribbean',\n",
    "        'Plurinational State of Bolivia': 'Latin America and the Caribbean',\n",
    "        'Suriname': 'Latin America and the Caribbean',\n",
    "        'Trinidad and Tobago': 'Latin America and the Caribbean',\n",
    "        'Belize': 'Latin America and the Caribbean',\n",
    "        'Paraguay': 'Latin America and the Caribbean',\n",
    "        'Ecuador': 'Latin America and the Caribbean',\n",
    "        'El Salvador': 'Latin America and the Caribbean',\n",
    "        'Guatemala': 'Latin America and the Caribbean',\n",
    "        'Nicaragua': 'Latin America and the Caribbean',\n",
    "        'Honduras': 'Latin America and the Caribbean',\n",
    "        'Panama': 'Latin America and the Caribbean',\n",
    "        'Uruguay': 'Latin America and the Caribbean',\n",
    "\n",
    "        'Myanmar': 'South-eastern Asia',\n",
    "        'Brunei Darussalam': 'South-eastern Asia',\n",
    "        'Timor-Leste': 'South-eastern Asia',\n",
    "        'Singapore': 'South-eastern Asia',\n",
    "        'Cambodia': 'South-eastern Asia',\n",
    "        \"Lao People's Democratic Republic\": 'South-eastern Asia',\n",
    "        'Malaysia': 'South-eastern Asia',\n",
    "        'Thailand': 'South-eastern Asia',\n",
    "\n",
    "        'Mongolia': 'Eastern Asia',\n",
    "        \"Democratic People's Republic of Korea\": 'Eastern Asia',\n",
    "        'Republic of Korea': 'Eastern Asia',\n",
    "\n",
    "        'Maldives': 'Southern Asia',\n",
    "        'Mauritius': 'Southern Asia',\n",
    "        'Bhutan': 'Southern Asia',\n",
    "\n",
    "        'Bahamas': 'Northern America',\n",
    "        'Canada': 'Northern America',\n",
    "\n",
    "        'Albania': 'Southern Europe',\n",
    "        'Andorra': 'Southern Europe',\n",
    "        'Malta': 'Southern Europe',\n",
    "        'Slovenia': 'Southern Europe',\n",
    "        'Bosnia and Herzegovina': 'Southern Europe',\n",
    "        'Croatia': 'Southern Europe',\n",
    "        'Cyprus': 'Southern Europe',\n",
    "        'Greece': 'Southern Europe',\n",
    "        'Spain': 'Southern Europe',\n",
    "\n",
    "        'Czech Republic': 'Eastern Europe',\n",
    "        'Estonia': 'Eastern Europe',\n",
    "        'Lithuania': 'Eastern Europe',\n",
    "        'Belarus': 'Eastern Europe',\n",
    "        'Moldova': 'Eastern Europe',\n",
    "        'Latvia': 'Eastern Europe',\n",
    "        'Poland': 'Eastern Europe',\n",
    "        'Romania': 'Eastern Europe',\n",
    "        'Slovakia': 'Eastern Europe',\n",
    "        'Ukraine': 'Eastern Europe',\n",
    "        'Russia': 'Eastern Europe',\n",
    "\n",
    "        'Bahrain': 'Western Asia',\n",
    "        'Iraq': 'Western Asia',\n",
    "        'Kuwait': 'Western Asia',\n",
    "        'Lebanon': 'Western Asia',\n",
    "        'Oman': 'Western Asia',\n",
    "        'Qatar': 'Western Asia',\n",
    "        'Armenia': 'Western Asia',\n",
    "        'Azerbaijan': 'Western Asia',\n",
    "        'Georgia': 'Western Asia',\n",
    "        'Israel': 'Western Asia',\n",
    "        'Jordan': 'Western Asia',\n",
    "        'Saudi Arabia': 'Western Asia',\n",
    "        'Turkey': 'Western Asia',\n",
    "        'United Arab Emirates': 'Western Asia',\n",
    "        'Yemen': 'Western Asia',\n",
    "        'Iran (Islamic Republic of)': 'Western Asia',\n",
    "\n",
    "        'Belgium': 'Western Europe',\n",
    "        'Denmark': 'Western Europe',\n",
    "        'Finland': 'Western Europe',\n",
    "        'Germany': 'Western Europe',\n",
    "        'Liechtenstein': 'Western Europe',\n",
    "        'Netherlands': 'Western Europe',\n",
    "        'Portugal': 'Western Europe',\n",
    "        'Luxembourg': 'Western Europe',\n",
    "        'United Kingdom of Great Britain and Northern Ireland': 'Western Europe',\n",
    "        'Austria': 'Western Europe',\n",
    "        'Iceland': 'Western Europe',\n",
    "        'Ireland': 'Western Europe',\n",
    "        'Norway': 'Western Europe'\n",
    "    }\n",
    "\n",
    "    for country, subregion in subregion_mapping.items():\n",
    "        final_df.loc[df['Country'] == country, 'Subregion'] = subregion\n",
    "\n",
    "    return final_df\n",
    "\n",
    "final_df = assign_subregions(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f285730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import TargetEncoder\n",
    "\n",
    "def preprocess_data(final_df, df_housing, assign_subregions):\n",
    "    final_df['Subregion'] = final_df['Country'].map(country_to_subregion_mapping)\n",
    "    \n",
    "    final_df['Subregion'] = final_df['Subregion'].fillna('Unknown')\n",
    "    \n",
    "    final_df.fillna(0, inplace=True)\n",
    "    \n",
    "    subregion_target_encoding = final_df.groupby('Subregion')['W'].mean()\n",
    "    final_df['Subregion_encoded'] = final_df['Subregion'].map(subregion_target_encoding)\n",
    "    \n",
    "    final_df = final_df.merge(df_housing, on=['Country', 'Year'], how='left')\n",
    "    \n",
    "    final_df = final_df.fillna(method='ffill')\n",
    "    \n",
    "    final_df = final_df.fillna(0)\n",
    "\n",
    "    encoder = TargetEncoder()\n",
    "\n",
    "    encoder.fit(final_df['Country'].values.reshape(-1, 1), final_df['W'])\n",
    "\n",
    "    final_df['Country_encoded'] = encoder.transform(final_df['Country'].values.reshape(-1, 1))\n",
    "    \n",
    "    final_df['deaths_per_disaster'] = (\n",
    "        (final_df['deaths_Animal incident'] + final_df['deaths_Drought'] + \n",
    "         final_df['deaths_Earthquake'] + final_df['deaths_Epidemic'] +\n",
    "         final_df['deaths_Extreme temperature'] + final_df['deaths_Flood'] + \n",
    "         final_df['deaths_Glacial lake outburst flood'] + final_df['deaths_Impact'] + \n",
    "         final_df['deaths_Infestation'] + final_df['deaths_Mass movement (dry)'] + \n",
    "         final_df['deaths_Mass movement (wet)'] + final_df['deaths_Storm'] + \n",
    "         final_df['deaths_Volcanic activity'] + final_df['deaths_Wildfire']) /\n",
    "        (final_df['count_Animal incident'] + final_df['count_Drought'] +\n",
    "         final_df['count_Earthquake'] + final_df['count_Epidemic'] +\n",
    "         final_df['count_Extreme temperature'] + final_df['count_Flood'] + \n",
    "         final_df['count_Glacial lake outburst flood'] + final_df['count_Impact'] + \n",
    "         final_df['count_Infestation'] + final_df['count_Mass movement (dry)'] +\n",
    "         final_df['count_Mass movement (wet)'] + final_df['count_Storm'] +\n",
    "         final_df['count_Volcanic activity'] + final_df['count_Wildfire'])\n",
    "    )\n",
    "    \n",
    "    final_df['affected_per_disaster'] = (\n",
    "        (final_df['affected_Animal incident'] + final_df['affected_Drought'] + \n",
    "         final_df['affected_Earthquake'] + final_df['affected_Epidemic'] +\n",
    "         final_df['affected_Extreme temperature'] + final_df['affected_Flood'] + \n",
    "         final_df['affected_Glacial lake outburst flood'] + final_df['affected_Impact'] + \n",
    "         final_df['affected_Infestation'] + final_df['affected_Mass movement (dry)'] + \n",
    "         final_df['affected_Mass movement (wet)'] + final_df['affected_Storm'] + \n",
    "         final_df['affected_Volcanic activity'] + final_df['affected_Wildfire']) /\n",
    "        (final_df['count_Animal incident'] + final_df['count_Drought'] +\n",
    "         final_df['count_Earthquake'] + final_df['count_Epidemic'] +\n",
    "         final_df['count_Extreme temperature'] + final_df['count_Flood'] + \n",
    "         final_df['count_Glacial lake outburst flood'] + final_df['count_Impact'] + \n",
    "         final_df['count_Infestation'] + final_df['count_Mass movement (dry)'] +\n",
    "         final_df['count_Mass movement (wet)'] + final_df['count_Storm'] +\n",
    "         final_df['count_Volcanic activity'] + final_df['count_Wildfire'])\n",
    "    )\n",
    "    \n",
    "    final_df['disaster_severity_index'] = (\n",
    "        (final_df['deaths_Animal incident'] + final_df['deaths_Drought'] + \n",
    "         final_df['deaths_Earthquake'] + final_df['deaths_Epidemic'] +\n",
    "         final_df['deaths_Extreme temperature'] + final_df['deaths_Flood'] + \n",
    "         final_df['deaths_Glacial lake outburst flood'] + final_df['deaths_Impact'] + \n",
    "         final_df['deaths_Infestation'] + final_df['deaths_Mass movement (dry)'] + \n",
    "         final_df['deaths_Mass movement (wet)'] + final_df['deaths_Storm'] + \n",
    "         final_df['deaths_Volcanic activity'] + final_df['deaths_Wildfire'] +\n",
    "         final_df['affected_Animal incident'] + final_df['affected_Drought'] +\n",
    "         final_df['affected_Earthquake'] + final_df['affected_Epidemic'] +\n",
    "         final_df['affected_Extreme temperature'] + final_df['affected_Flood'] +\n",
    "         final_df['affected_Glacial lake outburst flood'] + final_df['affected_Impact'] +\n",
    "         final_df['affected_Infestation'] + final_df['affected_Mass movement (dry)'] +\n",
    "         final_df['affected_Mass movement (wet)'] + final_df['affected_Storm'] +\n",
    "         final_df['affected_Volcanic activity'] + final_df['affected_Wildfire']) /\n",
    "        (final_df['count_Animal incident'] + final_df['count_Drought'] +\n",
    "         final_df['count_Earthquake'] + final_df['count_Epidemic'] +\n",
    "         final_df['count_Extreme temperature'] + final_df['count_Flood'] + \n",
    "         final_df['count_Glacial lake outburst flood'] + final_df['count_Impact'] +\n",
    "         final_df['count_Infestation'] + final_df['count_Mass movement (dry)'] +\n",
    "         final_df['count_Mass movement (wet)'] + final_df['count_Storm'] +\n",
    "         final_df['count_Volcanic activity'] + final_df['count_Wildfire'])\n",
    "    )\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4d00449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from joblib import dump\n",
    "\n",
    "def train_and_save_model(df, target_column, drop_columns, model_filename, test_size=0.3, random_state=42):\n",
    "    \n",
    "    X = df.drop(columns=drop_columns)\n",
    "    y = df[target_column]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('model', RandomForestRegressor(n_estimators=100, random_state=random_state))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    dump(pipeline, model_filename)\n",
    "\n",
    "    print(f\"Model saved to {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdc5debb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to disaster_risk_calculator_model.joblib\n"
     ]
    }
   ],
   "source": [
    "drop_columns = ['W', 'Year', 'ISO3.Code', 'Country', 'Subregion']\n",
    "target_column = 'W'\n",
    "model_filename = 'disaster_risk_calculator_model.joblib'\n",
    "\n",
    "train_and_save_model(final_df, target_column, drop_columns, model_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
